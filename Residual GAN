import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import os.path
from tqdm import tqdm

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
PATH_gan = r"C:\Users\netam\Documents\Python Scripts\gan_project"


class GeneratorR(nn.Module):
    def __init__(self):
        super(GeneratorR, self).__init__()

        self.fc1 = nn.Linear(6, 32)
        torch.nn.init.normal_(self.fc1.weight, mean=0.0, std=(2/6)**0.5)
        self.fc2 = nn.Linear(32, 16)
        torch.nn.init.normal_(self.fc2.weight, mean=0.0, std=(2/32)**0.5)
        self.fc3 = nn.Linear(16, 8)
        torch.nn.init.normal_(self.fc3.weight, mean=0.0, std=(2/16)**0.5)
        self.fc4 = nn.Linear(8, 5)
        torch.nn.init.xavier_uniform(self.fc4.weight)

    def forward(self, x, training=False):

        x = F.leaky_relu(self.fc1(x))
        x = F.leaky_relu(self.fc2(x))
        x = F.leaky_relu(self.fc3(x))
        x = torch.tanh(self.fc4(x))
        return x

class DiscriminatorR(nn.Module):
    def __init__(self):
        super(DiscriminatorR, self).__init__()

        self.fc1 = nn.Linear(5, 32)
        torch.nn.init.normal_(self.fc1.weight, mean=0.0, std=(2/5)**0.5)
        self.fc2 = nn.Linear(32, 32)
        torch.nn.init.normal_(self.fc2.weight, mean=0.0, std=(2/32)**0.5)
        self.fc3 = nn.Linear(64, 32)
        torch.nn.init.normal_(self.fc3.weight, mean=0.0, std=(2/32)**0.5)
        self.fc4 = nn.Linear(32, 32)
        torch.nn.init.normal_(self.fc4.weight, mean=0.0, std=(2/32)**0.5)
        self.fc5 = nn.Linear(64, 32)
        torch.nn.init.normal_(self.fc5.weight, mean=0.0, std=(2/32)**0.5)
        self.fc6 = nn.Linear(32, 1)
        torch.nn.init.xavier_uniform(self.fc6.weight)

    def forward(self, x, training=False):

        output = F.leaky_relu(self.fc1(x))
        output2 = F.leaky_relu(self.fc2(output))
        output3 = torch.cat((output, output2), 1)
        output4 = F.leaky_relu(self.fc3(output3))
        output5 = F.leaky_relu(self.fc4(output4))
        output6 = torch.cat((output4, output5), 1)
        output7 = F.leaky_relu(self.fc5(output6))
        x = torch.sigmoid(self.fc6(output7))
        return x

class GanModelR(nn.Module):
    def __init__(self):
        super(GanModelR, self).__init__()
        self.generator = GeneratorR()
        self.discriminator = DiscriminatorR()

    def training_gan(self, trainloader, lr, beta1, b_size, epoch, epoch_dis, fixed_noise,opt_name):
        try:
            num_epochs= epoch
            criterion = nn.BCELoss()
            optimizerD = optim.Adam(self.discriminator.parameters(), lr=lr, betas=(beta1, 0.999))
            optimizerG = optim.Adam(self.generator.parameters(), lr=lr, betas=(beta1, 0.999))

            real_label = 1.0
            fake_label = 0.

            G_losses = []
            D_losses = []
            D_real_losses = []
            D_fake_losses = []

            for e in  tqdm(range(1, num_epochs + 1)):
                print(f"'Epoch {e}' ")
                for j, (data, _) in enumerate(trainloader):
                    for i in range(epoch_dis):
                        data = data.to(device)
                        # Update discriminator network
                        ## Train with real batch
                        self.discriminator.train()
                        self.generator.eval()
                        self.discriminator.zero_grad()
                        real_features = data
                        label = torch.full((int(real_features.size()[0]),), real_label, dtype=torch.float, device=device)
                        output = self.discriminator(real_features, training=True).view(-1)
                        error_D_real = criterion(output, label)
                        error_D_real.backward()
                        dis_real = output.mean().item()
                        ## Train with fake batch
                        noise = torch.from_numpy(np.random.normal(0, 0.2, [int(real_features.size()[0]), 6])).type(torch.FloatTensor)
                        noise = noise.to(device)
                        fake = self.generator(noise, training=False)
                        label.fill_(fake_label).type(torch.FloatTensor)
                        output = self.discriminator(fake.detach(), training=True).view(-1)
                        error_D_fake = criterion(output, label)
                        error_D_fake.backward()
                        dis_fake1 = output.mean().item()
                        errD = error_D_real + error_D_fake
                        optimizerD.step()

                    # Update generator network:
                    self.generator.train()
                    self.discriminator.eval()
                    self.generator.zero_grad()
                    label = torch.full((int(real_features.size()[0]),), real_label, dtype=torch.float, device=device)
                    noise = torch.from_numpy(np.random.normal(0, 0.2, [int(real_features.size()[0]), 6])).type(torch.FloatTensor)
                    noise=noise.to(device)
                    fake = self.generator(noise, training=True)
                    output = self.discriminator(fake, training=False).view(-1)
                    errG = criterion(output, label)
                    errG.backward()
                    dis_fake2 = output.mean().item()
                    errG = errG * 0.99
                    optimizerG.step()

                    # Save Losses
                    G_losses.append(errG.item())
                    D_losses.append(errD.item())
                    D_real_losses.append(error_D_real.item())
                    D_fake_losses.append(error_D_fake.item())

                    # Check losses
                    if (e % 50 == 0) or (e == num_epochs):
                        print(f"[{e}/{num_epochs}][{i}/{b_size}]\tLoss_D: {errD.item()} \tLoss_G:{errG.item()} \tDis_for_real_data:{dis_real} \tDis_for_fake_data:{dis_fake1}/ {dis_fake2}")

        except:
            torch.save(self, os.path.join(PATH_gan, str(opt_name)+".pth"))
        else:
            print("Training is complete")
            torch.save(self, os.path.join(PATH_gan, str(opt_name)+".pth"))
        return G_losses, D_losses, D_real_losses, D_fake_losses
