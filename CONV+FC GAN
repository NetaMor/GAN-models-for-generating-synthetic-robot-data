import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import os.path
from tqdm import tqdm

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
PATH_gan = r"C:\Users\netam\Documents\Python Scripts\gan_project"

class GeneratorConv(nn.Module):
    def __init__(self):
        super(GeneratorConv, self).__init__()
        self.cnn1 = nn.ConvTranspose1d(1, 32, kernel_size=2, stride=1, padding=0)
        self.cnn2 = nn.ConvTranspose1d(32, 64, kernel_size=2, stride=1, padding=0)
        self.cnn3 = nn.ConvTranspose1d(64, 128, kernel_size=2, stride=1, padding=0) 
        self.fc1 = nn.Linear(5*128, 32)
        torch.nn.init.normal_(self.fc1.weight, mean=0.0, std=(2 / (5*128)) ** 0.5)
        self.fc2 = nn.Linear(32, 5)
        torch.nn.init.xavier_uniform(self.fc2.weight)

    def forward(self, x, training=False):
        p = 0.2
        x_c1 = F.leaky_relu(self.cnn1(x))
        x_c2 = F.leaky_relu(self.cnn2(x_c1))
        x_c3 = F.leaky_relu(self.cnn3(x_c2))
        x_c3 = x_c3.view(-1, 128*5)
        x_flatten = torch.squeeze(x_c3)
        x_f1 = F.leaky_relu(self.fc1(x_flatten))
        x_f2 = torch.tanh(self.fc2(x_f1))
        return x_f2

class DiscriminatorConv(nn.Module):
    def __init__(self):
        super(DiscriminatorConv, self).__init__()

        self.cnn1 = nn.Conv1d(1, 128, kernel_size=2, stride=1, padding=0)#256*1*5--> 256*128*4
        self.cnn2 = nn.Conv1d(128, 64, kernel_size=2, stride=1, padding=0)  # 256*128*4--> 256*64*3
        self.cnn3 = nn.Conv1d(64, 32, kernel_size=2, stride=1, padding=0)  # 256*64*3--> 256*32*2
        self.fc1 = nn.Linear(32*2, 16)
        torch.nn.init.normal_(self.fc1.weight, mean=0.0, std=(2 / (32*2)) ** 0.5)
        self.fc2 = nn.Linear(16, 1)
        torch.nn.init.xavier_uniform(self.fc2.weight)

    def forward(self, x, training=False):
        x_c1 = F.leaky_relu(self.cnn1(x))
        x_c2 = F.leaky_relu(self.cnn2(x_c1))
        x_c3 = F.leaky_relu(self.cnn3(x_c2))
        x_c3 = x_c3.view(-1, 32*2)
        x_flatten = torch.squeeze(x_c3)
        x_f1 = F.leaky_relu(self.fc1(x_flatten))
        x_f2 = torch.sigmoid(self.fc2(x_f1))
        return x_f2

class GanModelConv(nn.Module):
    def __init__(self):
        super(GanModelConv, self).__init__()
        self.generator = GeneratorConv()
        self.discriminator = DiscriminatorConv()
